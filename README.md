# Scalable Recommendation Engine (FastAPI + Redis + Docker)

A high-performance, asynchronous recommendation backend designed to handle **10k+ requests per second**. This project implements a **Retrieval-Ranking** architecture using **FastAPI** for orchestration, **Redis** for feature caching, and a **Wide & Deep** model architecture for scoring.

## ðŸš€ Key Features

*   **Scalable Architecture:** Async/Sync hybrid design with specialized Batch Processing logic to handle high-throughput inference.
*   **Production Ready:** Dockerized setup with `gunicorn` + `uvicorn` workers.
*   **Low Latency:** Uses Redis Pipeline for sub-millisecond feature fetching.
*   **Clean Design:** Follows "Clean Architecture" principles (Service Layer, Dependency Injection, Pydantic Schemas).
*   **Wide & Deep Support:** Logic in place to handle sparse (categorical) and deep (dense) features.

## ðŸ›  Tech Stack

*   **Framework:** FastAPI
*   **Cache / Feature Store:** Redis (Alpine)
*   **Vector DB:** Qdrant (Integrated & Ready)
*   **Containerization:** Docker & Docker Compose
*   **ML Runtime:** ONNX Runtime (Mocked for demo)

## ðŸ“‚ Project Structure

```text
recommendation_engine/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/          # Route handlers & Dependency Injection
â”‚   â”œâ”€â”€ core/         # Config & Lifespan (Startup) logic
â”‚   â”œâ”€â”€ ml/           # Model wrappers & ONNX interaction
â”‚   â”œâ”€â”€ services/     # Business logic (Batching, Retrieval)
â”‚   â””â”€â”€ schemas/      # Pydantic data models
â”œâ”€â”€ artifacts/        # Model files (dummy_model)
â”œâ”€â”€ Dockerfile        # Multi-stage build
â””â”€â”€ docker-compose.yml
